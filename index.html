<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Advanced Voice Assistant</title>
  <style>
    body {
      margin: 0;
      font-family: Arial, sans-serif;
      background-color: #121212;
      color: #e0e0e0;
      overflow: hidden;
      display: flex;
      align-items: center;
      justify-content: center;
      height: 100vh;
    }

    .personal-assistant {
      position: relative;
      display: flex;
      align-items: center;
      justify-content: center;
      flex-direction: column;
      width: 100%;
      text-align: center;
    }

    .felix {
      position: absolute;
      bottom: 50px;
      width: 110px;
      height: 95px;
      border-radius: 45%;
      border: 3px solid #fff;
      box-shadow: 0 0 5px rgba(255, 255, 255, 0.5);
      animation: breathe-and-jump 3s linear infinite;
      cursor: pointer;
      z-index: 1;
      background: linear-gradient(to bottom, #5fc, #1a8);
    }

    .felix::before {
      content: '';
      position: absolute;
      top: -1px;
      left: -1px;
      width: calc(100% + 3px);
      height: calc(100% + 2px);
      background: linear-gradient(to bottom, #5fc, #1a8);
      border-radius: 45%;
      opacity: 0;
      transition: 0.3s linear all;
    }

    .felix.active::before {
      opacity: 1;
    }

    .felix > .eyes {
      position: relative;
    }

    .felix > .eyes > .eye {
      position: absolute;
      top: 20px;
      width: 20px;
      height: 25px;
      border-radius: 15px;
      background-color: #fff;
      box-shadow: 0 0 7px rgba(255, 255, 255, 0.5);
      animation: blink 5s linear infinite;
    }

    .felix > .eyes > .eye.left { left: 25%; }
    .felix > .eyes > .eye.right { right: 25%; }

    .response-frame, .caption-frame {
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      display: flex;
      align-items: center;
      justify-content: center;
      background-color: #000c;
      z-index: -1;
      opacity: 0;
      transition: opacity 0.3s linear;
      color: #fff;
      font-size: 18px;
    }

    .response-frame.active, .caption-frame.active {
      z-index: 1000;
      opacity: 1;
    }

    .response-frame > .lead, .caption-frame > .caption {
      padding: 10px;
      border-radius: 5px;
      background-color: #333;
    }

    .response-frame > .fas, .caption-frame > .fas {
      width: 50px;
      height: 50px;
      font-size: 25px;
      line-height: 45px;
      border: 2px solid #fff;
      border-radius: 50%;
      cursor: pointer;
      box-shadow: 0 0 10px #fff, 0 0 5px #fff inset;
      transition: 0.3s linear all;
      display: flex;
      align-items: center;
      justify-content: center;
    }

    .response-frame > .fas:hover, .caption-frame > .fas:hover {
      border: 2px solid #f55;
      box-shadow: 0 0 15px #f55, 0 0 5px #f55 inset;
      color: #f55;
    }

    @keyframes blink {
      0%, 100% { transform: scale(1, 0.05); }
      5%, 95% { transform: scale(1, 1); }
    }

    @keyframes breathe-and-jump {
      0%, 40%, 80%, 100% { height: 95px; transform: translateY(0); }
      20%, 60%, 70%, 90% { height: 100px; transform: translateY(-5px); }
    }
  </style>
</head>
<body>
  <div class="personal-assistant">
    <div id="felix" class="felix">
      <div class="eyes">
        <div class="eye left"></div>
        <div class="eye right"></div>
      </div>
    </div>
    <div class="response-frame">
      <div class="lead">Listening...</div>
      <div class="fas">&#xf057;</div>
    </div>
    <div class="caption-frame">
      <div class="caption">Say something...</div>
      <div class="fas">&#xf057;</div>
    </div>
  </div>

  <script>
    if (!('webkitSpeechRecognition' in window) || !('speechSynthesis' in window)) {
      alert('Speech recognition or synthesis not supported in this browser.');
    }

    const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    const synthesis = window.speechSynthesis;
    const felix = document.getElementById('felix');
    const responseFrame = document.querySelector('.response-frame');
    const captionFrame = document.querySelector('.caption-frame');
    const closeResponseBtn = responseFrame.querySelector('.fas');
    const closeCaptionBtn = captionFrame.querySelector('.fas');

    recognition.interimResults = true;
    recognition.lang = 'en-US';
    recognition.continuous = true;

    let silenceTimeout;
    let isListening = false;

    const responses = {
      hello: [
        'Hey there! How can I assist you today?',
        'Hello! What can I do for you?',
        'Hi! Need help with something?',
        'Greetings! How can I help?'
      ],
      weather: 'I can’t check the weather right now, but you can use a weather app for the latest updates.',
      joke: [
        'Why did the scarecrow win an award? Because he was outstanding in his field!',
        'Why don’t scientists trust atoms? Because they make up everything!',
        'What do you call fake spaghetti? An impasta!'
      ],
      thank: 'You\'re welcome!',
      help: 'I can help with various tasks like answering questions, telling jokes, and more.',
      unknown: 'I\'m sorry, I didn\'t understand that command.',
      goodbye: 'Goodbye! Have a great day!',
      time: () => {
        const now = new Date();
        return `The current time is ${now.toLocaleTimeString()}.`;
      },
      date: () => {
        const now = new Date();
        return `Today’s date is ${now.toLocaleDateString()}.`;
      }
    };

    function getRandomResponse(responses) {
      return responses[Math.floor(Math.random() * responses.length)];
    }

    function handleVoiceCommand(command) {
      let responseText = responses.unknown;

      if (command.includes('hello')) {
        responseText = getRandomResponse(responses.hello);
      } else if (command.includes('weather')) {
        responseText = responses.weather;
      } else if (command.includes('joke')) {
        responseText = getRandomResponse(responses.joke);
      } else if (command.includes('thank you') || command.includes('thanks')) {
        responseText = responses.thank;
      } else if (command.includes('help') || command.includes('what can you do')) {
        responseText = responses.help;
      } else if (command.includes('goodbye') || command.includes('bye')) {
        responseText = responses.goodbye;
        deactivateAssistant();
      } else if (command.includes('time')) {
        responseText = responses.time();
      } else if (command.includes('date')) {
        responseText = responses.date();
      }

      return responseText;
    }

    function updateCaption(text) {
      captionFrame.querySelector('.caption').textContent = text;
      captionFrame.classList.add('active');
    }

    function startListening() {
      if (!isListening) {
        recognition.start();
        isListening = true;
      }
    }

    function stopListening() {
      if (isListening) {
        recognition.stop();
        isListening = false;
      }
    }

    recognition.onresult = (event) => {
      let command = '';
      for (const result of event.results) {
        if (result.isFinal) {
          command = result[0].transcript.toLowerCase().trim();
          console.log(`Heard: ${command}`);

          updateCaption(`You said: ${command}`);
          responseFrame.querySelector('.lead').textContent = 'Processing...';
          responseFrame.classList.add('active');

          const responseText = handleVoiceCommand(command);

          if (synthesis.speaking) {
            synthesis.cancel(); // Stop current speech if any
          }

          const utterance = new SpeechSynthesisUtterance(responseText);
          synthesis.speak(utterance);

          // Hide frames after response
          utterance.onend = () => {
            responseFrame.classList.remove('active');
            captionFrame.classList.remove('active');
            startListening(); // Restart listening after response
          };

          clearTimeout(silenceTimeout);
        }
      }
    };

    recognition.onerror = (event) => {
      console.error('Speech recognition error:', event.error);
      startListening(); // Restart listening on error
    };

    recognition.onend = () => {
      console.log('Speech recognition ended');
      startListening(); // Restart listening if recognition ends
    };

    closeResponseBtn.onclick = () => {
      responseFrame.classList.remove('active');
    };

    closeCaptionBtn.onclick = () => {
      captionFrame.classList.remove('active');
    };

    // Start listening automatically
    startListening();
  </script>
</body>
</html>
